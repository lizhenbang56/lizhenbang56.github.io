<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="zhbli">
<meta property="og:url" content="http://yoursite.com/page/10/index.html">
<meta property="og:site_name" content="zhbli">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="zhbli">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/page/10/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>zhbli</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">zhbli</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-fw fa-calendar"></i>Schedule</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-fw fa-sitemap"></i>Sitemap</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="fa fa-fw fa-heartbeat"></i>Commonweal 404</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/03/CVPR2020-Cooling-Shrinking-Attack-Blinding-the-Tracker-with-Imperceptible-Noises/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhbli">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zhbli">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/03/CVPR2020-Cooling-Shrinking-Attack-Blinding-the-Tracker-with-Imperceptible-Noises/" class="post-title-link" itemprop="url">[CVPR2020] Cooling-Shrinking Attack: Blinding the Tracker with Imperceptible Noises</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-03 09:20:33" itemprop="dateCreated datePublished" datetime="2020-05-03T09:20:33+08:00">2020-05-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-15 14:53:16" itemprop="dateModified" datetime="2020-08-15T14:53:16+08:00">2020-08-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tracking/" itemprop="url" rel="index"><span itemprop="name">Tracking</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tracking/Adversarial-Attack/" itemprop="url" rel="index"><span itemprop="name">Adversarial Attack</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>本文利用 cooling-shrinking attack method 攻击孪生网络跟踪器。</p>
<p>性能：</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/MasterBin-IIAU/CSA">https://github.com/MasterBin-IIAU/CSA</a></p>
</li>
<li><p>在三个数据库上进行攻击：OTB100、VOT2018、LaSOT。</p>
</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><code>Adversarial attack</code> 常分为两类：</p>
<ol>
<li>iterative-optimization-based atracks：进行梯度上升，最大化 adversarial objective function。</li>
<li>deep-network-based attacks：使用大量数据训练 adversarial perturbation-generator。</li>
</ol>
<p>本文提出的 cooling-shrinking attack method 学习有效的 perturbation generator，通过如下方式使跟踪失败：</p>
<ul>
<li>冷却 heatmap 中存在目标的 hot regions。</li>
<li>缩小目标边框。</li>
</ul>
<h2 id="Cooling-Shrinking-Attack"><a href="#Cooling-Shrinking-Attack" class="headerlink" title="Cooling-Shrinking Attack"></a>Cooling-Shrinking Attack</h2><p>本文提出 adversarial perturbation-generator 来欺骗 siamrpn++ 跟踪器，设计两种 perturbation-generator 分别攻击 search regions 和 template。</p>
<h3 id="Overall-Pipeline"><a href="#Overall-Pipeline" class="headerlink" title="Overall Pipeline"></a>Overall Pipeline</h3><img src="https://i.loli.net/2020/05/03/TltiZcINpuAxDG3.png" alt="image-20200503093629859" style="zoom:50%;" />

<p>由于攻击 template 和攻击 search regions 的过程非常相似，因此仅讨论攻击搜索区域：</p>
<ol>
<li><p>在训练过程中，首先将 $N$ 个预先裁剪好的未被扰动的搜索区域送入 perturbation-generator，从而向搜索区域添加难以察觉的噪声。</p>
</li>
<li><p>然后，将 perturbed search regions 与 clean template 送入 siamrpn++，生成 adversarial classification/regression maps。</p>
</li>
<li><p>Adversarial heatmaps 中的目标区域希望有较低的响应值。</p>
</li>
<li><p>为了得到这些区域，将 unperturbed search regions 送入网络，得到 clean heatmaps。</p>
</li>
<li><p>通过 adversarial cooling-shrinking loss 和 L2 loss 训练 perturbation-generator。</p>
</li>
</ol>
<h3 id="Cooling-Shrinking-Loss"><a href="#Cooling-Shrinking-Loss" class="headerlink" title="Cooling-Shrinking Loss"></a>Cooling-Shrinking Loss</h3><p>Cooling-shrinking loss 包括两部分：</p>
<ol>
<li>cooling loss $L_C$：用于  heatmaps $M_H$。冷却 heatmap 中存在目标的 hot regions。导致跟踪器丢失目标。</li>
<li>shrinking loss $L_S$：用于 regression maps $M_R$。缩小目标边框，引起累计误差，导致跟踪失败。</li>
</ol>
<p>为了确定目标的位置，引入 clean heatmaps $M^c_H$。</p>
<p>为了便于计算，将 heatmaps 转换成二维矩阵：</p>
<ol>
<li>clean heatmaps $M^c_H\rightarrow \widetilde{M^c_H}\in \mathbb R^{N\times2}$。</li>
<li>adversarial heatmaps $M^a_H\rightarrow \widetilde{M^a_H}\in \mathbb R^{N\times2}$。</li>
<li>adversarial regression maps $M^a_R\rightarrow \widetilde{M^a_R}\in \mathbb R^{N\times4}$。</li>
</ol>
<p>对 clean heatmaps 进行 softmax 并使用阈值得到 binary attention maps $\mathcal A$ 用于确定前景和背景。</p>
<p>算法流程为：</p>
<img src="https://i.loli.net/2020/05/03/WXc13NhlDATfyKw.png" alt="image-20200503102021919" style="zoom:50%;" />

<h3 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h3><h4 id="Network-Architectures"><a href="#Network-Architectures" class="headerlink" title="Network Architectures"></a>Network Architectures</h4><p>Perturbation-generator 采用 U-Net 架构。</p>
<p>网络通过 cooling loss、shrinking loss 和 L2 loss 训练，权重分别为 0.1，1 和 500。</p>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Adversarial-Attack-to-SiamRPNpp"><a href="#Adversarial-Attack-to-SiamRPNpp" class="headerlink" title="Adversarial Attack to SiamRPNpp"></a>Adversarial Attack to SiamRPNpp</h3><p>进行如下三组实验：</p>
<ol>
<li>仅攻击 search region</li>
<li>仅攻击 template</li>
<li>同时攻击 search region 和 template</li>
</ol>
<h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3><h4 id="Influence-of-Shrinking-Loss"><a href="#Influence-of-Shrinking-Loss" class="headerlink" title="Influence of Shrinking Loss"></a>Influence of Shrinking Loss</h4><p>进行三组对比试验：</p>
<ol>
<li>G-Template vs. G-Template-Regress</li>
<li>G-Search vs. G-Search-Regress</li>
<li>G-Template-Search vs. GTemplate-Search-Regress</li>
</ol>
<p>结论：shrinking loss 有助于攻击 search regions，但对攻击 template 可能有害。</p>
<h4 id="Influence-of-a-Discriminator"><a href="#Influence-of-a-Discriminator" class="headerlink" title="Influence of a Discriminator"></a>Influence of a Discriminator</h4><p>并未进行实验，只是说明，不使用 discriminator，对抗样本的扰动也是难以察觉的。</p>
<h3 id="Further-Discussions"><a href="#Further-Discussions" class="headerlink" title="Further Discussions"></a>Further Discussions</h3><h4 id="Noise-Pattern"><a href="#Noise-Pattern" class="headerlink" title="Noise Pattern"></a>Noise Pattern</h4><p>如图 10 所示，扰动主要集中在被跟踪的目标上，而其他区域几乎不受扰动。</p>
<img src="https://i.loli.net/2020/05/03/ALdcw79a1touTHe.png" alt="image-20200503101605838" style="zoom:50%;" />
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/02/arXiv1911-TracKlinic-Diagnosis-of-Challenge-Factors-in-Visual-Tracking/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhbli">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zhbli">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/02/arXiv1911-TracKlinic-Diagnosis-of-Challenge-Factors-in-Visual-Tracking/" class="post-title-link" itemprop="url">[arXiv1911] TracKlinic: Diagnosis of Challenge Factors in Visual Tracking</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-02 20:07:11" itemprop="dateCreated datePublished" datetime="2020-05-02T20:07:11+08:00">2020-05-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-13 18:30:44" itemprop="dateModified" datetime="2020-05-13T18:30:44+08:00">2020-05-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tracking/" itemprop="url" rel="index"><span itemprop="name">Tracking</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tracking/Debug/" itemprop="url" rel="index"><span itemprop="name">Debug</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <img src="https://i.loli.net/2020/05/02/X1PbLnE42jYxSC6.png" alt="image-20200502203810486" style="zoom:50%;" />

<img src="https://i.loli.net/2020/05/02/3oyYTlCa9xRmj74.png" alt="image-20200502204038762" style="zoom:50%;" />

<img src="https://i.loli.net/2020/05/02/Ymwo5yKdFpVb9DB.png" alt="image-20200502204727402" style="zoom:50%;" />

<img src="https://i.loli.net/2020/05/02/t1OIgnD6Qa5hEP7.png" alt="image-20200502203853862" style="zoom:50%;" />

<img src="https://i.loli.net/2020/05/02/buvKkONB5gFSqx4.png" alt="image-20200502205102752" style="zoom:50%;" />
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/02/ICCV2019-Graph-Convolutional-Tracking/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhbli">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zhbli">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/02/ICCV2019-Graph-Convolutional-Tracking/" class="post-title-link" itemprop="url">[ICCV2019] Graph Convolutional Tracking</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-02 16:15:13" itemprop="dateCreated datePublished" datetime="2020-05-02T16:15:13+08:00">2020-05-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-13 18:34:18" itemprop="dateModified" datetime="2020-05-13T18:34:18+08:00">2020-05-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tracking/" itemprop="url" rel="index"><span itemprop="name">Tracking</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tracking/Architecture/" itemprop="url" rel="index"><span itemprop="name">Architecture</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Graph-Convolutional-Tracking"><a href="#Graph-Convolutional-Tracking" class="headerlink" title="Graph Convolutional Tracking"></a>Graph Convolutional Tracking</h2><img src="https://i.loli.net/2020/05/13/wOBJ7QAbomSsq3x.png" alt="image-20200513183345624" style="zoom:50%;" />

<p>定义 $z$ 为尺寸是 $127\times 127$ 的 exemplar image，$x$ 为尺寸是 $255\times 255$ 的 search image。本文将 graph convolutional transformation 和孪生跟踪器结合到一起：</p>
<img src="https://i.loli.net/2020/05/02/DxowNZF1dGCHVJ3.png" alt="image-20200502161844838" style="zoom:50%;" />

<p>本文将 $\psi_{GCN}$ 分解为：</p>
<ul>
<li>Spatial-Temporal GCN (ST-GCN) $\psi_1$</li>
<li>ConText GCN (CT-GCN) $\psi_2$</li>
</ul>
<p>可得：</p>
<img src="https://i.loli.net/2020/05/02/rLUEOPdyAZgQRYa.png" alt="image-20200502162452244" style="zoom:50%;" />

<h3 id="Preliminary-Graph-Convolutional-Networks"><a href="#Preliminary-Graph-Convolutional-Networks" class="headerlink" title="Preliminary: Graph Convolutional Networks"></a>Preliminary: Graph Convolutional Networks</h3><p>设图有 $M$ 个节点，adjacency matrix 为 $\mathbf A\in \mathbb {R}^{M\times M}$，degree matrix 为 $\mathbf \Lambda_{ii}=\sum_j \mathbf A_{ij}$。图卷积的线性变化指 graph signal $\mathbf X\in\mathbb R^{D\times M}$ 与 filter $\mathbf W\in \mathbb R^{D\times C}$ 相乘：</p>
<img src="https://i.loli.net/2020/05/02/Gy5worNVpHvQAlR.png" alt="image-20200502163142599" style="zoom:50%;" />

<p>其中 $\mathbf X_{i\cdot}\in \mathbb{R}^D$ 是第 $i$ 个节点的特征表示。$\hat{\mathbf A} = \mathbf A + \mathbf I$。 $\hat{\mathbf \Lambda}_{ii}=\sum_j \hat{\mathbf A}_{ij}$。</p>
<p>输出是尺寸为 $C\times M$ 的矩阵 $\mathbf V$。</p>
<p>补充：图卷积的输出和输出，节点数不变，都是 $M$。</p>
<h3 id="Target-Appearance-Modeling-via-ST-GCN"><a href="#Target-Appearance-Modeling-via-ST-GCN" class="headerlink" title="Target Appearance Modeling via ST-GCN"></a>Target Appearance Modeling via ST-GCN</h3><p>设 exemplar images 的 embeddings 为 ${\mathbf Z_i}_{i=t-1}^{t-T}$，其中 $\mathbf Z_i\in \mathbb R^{D_1\times M_z}$，$D_1$ 表示特征维度，$M_z$ 表示 parts 的数量。我们将特征图 $\mathbf Z_i$ 中每个 $D_1\times 1\times 1$ 的向量看作一个 target part。</p>
<p>构造无向图 $\mathcal{G_1=(V_1,E_1)}$。</p>
<p>节点集合 $\mathcal V_1 = {v_{ij}|i=t-1,…,t-T,j=1,…,M_z}$。</p>
<p>包括两种形式的边：</p>
<ol>
<li>Spatial edges $\mathcal E^S_1$ 表示每帧中的 intra-exemplar connection：$\mathcal E_1^S = {v_{ij}v_{ik}|1 \le j,k\le M_z,j \ne k}$。这是全连通图。</li>
<li>Temporal edges $\mathcal E_1^T = {v_{ij}v_{i+1,j}}$：相邻帧中，连接同一位置的 parts。 </li>
</ol>
<p>ST-GCN 为：</p>
<img src="https://i.loli.net/2020/05/02/jtn2TOPv9dJBoD7.png" alt="image-20200502164050191" style="zoom:50%;" />

<p>其中，$\hat{\mathbf{Z}}_i\in \mathbb R^{D_2\times M_z}$，$\mathbf{V}_1\in \mathbb R^{D_2\times M_z}$。</p>
<h3 id="Target-Feature-Adaption-via-CT-GCN"><a href="#Target-Feature-Adaption-via-CT-GCN" class="headerlink" title="Target Feature Adaption via CT-GCN"></a>Target Feature Adaption via CT-GCN</h3><p>作用：整合当前搜索图像的上下文信息。</p>
<p>得到 搜索图像的特征 $\mathbf X_t\in \mathbb R^{D_1\times M_x}$ 后，为了获得全局信息，对其进行卷积后全局池化得到向量 $\mathbf x_t$，再做反卷积得到 $\hat{\mathbf X}_t$，与 $\mathbf{V}_1$ 尺寸相同，并通过逐元素相加融合两者：</p>
<img src="https://i.loli.net/2020/05/02/z4GvTpXyadiOmeN.png" alt="image-20200502181142152" style="zoom:50%;" />

<p>邻接矩阵为：</p>
<img src="https://i.loli.net/2020/05/02/dbrjkyXocBUVwRQ.png" alt="image-20200502181249012" style="zoom:50%;" />
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/02/ICLR2019-META-LEARNING-WITH-LATENT-EMBEDDING-OPTIMIZATION/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhbli">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zhbli">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/02/ICLR2019-META-LEARNING-WITH-LATENT-EMBEDDING-OPTIMIZATION/" class="post-title-link" itemprop="url">ICLR2019 META-LEARNING WITH LATENT EMBEDDING OPTIMIZATION</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-05-02 13:43:49 / Modified: 15:57:52" itemprop="dateCreated datePublished" datetime="2020-05-02T13:43:49+08:00">2020-05-02</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>现有 meta-learning 算法的问题：由于数据量极少，而参数空间维度很高，这使得算法性能受到影响。</p>
<p>本文的解决方案：学习 data-dependent latent generative representation。提出 latent embedding optimization (LEO)，将基于梯度的自适应过程与模型参数的高维空间解耦。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>基于优化的元学习方法旨在找到一组模型参数，可以通过几步梯度下降来适应一个任务。</p>
<p>但是，仅使用几个样本类计算高位参数空间中的梯度会导致泛化困难。</p>
<p>本文提出 LEO，学习模型参数的低维潜在嵌入，并在此空间中执行基于优化的元学习。</p>
<h2 id="MODEL"><a href="#MODEL" class="headerlink" title="MODEL"></a>MODEL</h2><h3 id="PROBLEM-DEFINITION"><a href="#PROBLEM-DEFINITION" class="headerlink" title="PROBLEM DEFINITION"></a>PROBLEM DEFINITION</h3><p>每个 task instance $\mathcal T_i$ 是采样自  task distribution $p(\mathcal T)$ 的分类问题。任务划分 a training meta-set $\mathcal S^{tr}$ , validation meta-set $S^{val}$ 和 test meta-set $S^{test}$。每个 task instance $\mathcal T_i$ 由 training set $\mathcal D^{tr}$ 和 validation set $\mathcal D^{val}$ 组成。训练集2 $\mathcal D^{tr} = {(\mathbf x^k_n, y^k_n)|k=1…K;n=1…N}$。验证集包含相同类别的其他样本。</p>
<h3 id="MODEL-AGNOSTIC-META-LEARNING"><a href="#MODEL-AGNOSTIC-META-LEARNING" class="headerlink" title="MODEL-AGNOSTIC META-LEARNING"></a>MODEL-AGNOSTIC META-LEARNING</h3><p>MAML 是与本文相关的方法。对于一个模型 $f_\theta$，目的是找到参数 $\theta$，经过几次优化便可适应采样自同一 <code>distribution</code> 的 <code>task</code>。通过可微分的函数，将参数调整为  task-specific model parameters $θ’_i$，通常的更新方式为（公式 1）：</p>
<img src="https://i.loli.net/2020/05/02/MJaUvfgWGdsZmjN.png" alt="image-20200502143727821" style="zoom:50%;" />

<p>其中，$\mathcal G$ 通常是在 few-shot training set $\mathcal D^{tr}$ 上执行一次梯度下降：$\theta’_i=\theta-\alpha \nabla_\theta\mathcal L^{tr}_{\mathcal T_i}(f_\theta)$。</p>
<p>在 meta-training 时，更新参数 $\theta$ 以降低在 validation set $\mathcal D^{val}$ 上的误差：</p>
<img src="https://i.loli.net/2020/05/02/uYzHdO5qWR98c4A.png" alt="image-20200502144405743" style="zoom:50%;" />

<p>这一方法描述了基于优化的元学习的主要内容：</p>
<ul>
<li>initialization</li>
<li>adaptation procedure (inner loop)：公式 1。</li>
<li>termination (outer loop)：公式 2。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/02/ECCV2018-Triplet-Loss-in-Siamese-Network-for-Object-Tracking/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhbli">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zhbli">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/02/ECCV2018-Triplet-Loss-in-Siamese-Network-for-Object-Tracking/" class="post-title-link" itemprop="url">[ECCV2018] Triplet Loss in Siamese Network for Object Tracking</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-02 10:27:50" itemprop="dateCreated datePublished" datetime="2020-05-02T10:27:50+08:00">2020-05-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-13 18:28:26" itemprop="dateModified" datetime="2020-05-13T18:28:26+08:00">2020-05-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tracking/" itemprop="url" rel="index"><span itemprop="name">Tracking</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tracking/Loss/" itemprop="url" rel="index"><span itemprop="name">Loss</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>现有跟踪算法的问题：孪生网络仅用了样本的成对关系，忽略了三元组关系。</p>
<p>本文的解决方案：将 triplet loss 应用到 3 个孪生跟踪器（SiamFC、CFnet2 和 SiamImp），验证了有效性。</p>
<p>性能：</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/shenjianbing/TripletTracking">https://github.com/shenjianbing/TripletTracking</a></p>
</li>
<li><p>在 3 个数据集上进行实验： OTB-2013，OTB-100 和 VOT-2017。</p>
</li>
</ul>
<h2 id="Siamese-network-with-triplet-loss"><a href="#Siamese-network-with-triplet-loss" class="headerlink" title="Siamese network with triplet loss"></a>Siamese network with triplet loss</h2><p>可以将 SiamFC 中的  instances set（即 instance input）$\mathcal X$ 拆分成 positive instances set $\mathcal X_p$ 和 negative instances set $\mathcal X_n$。</p>
<p>类似地，将  exemplar-instance pairs 的 similarity score set $V$ 划分成 positive score set $\mathcal V_p$ 和 negative score set $\mathcal V_n$。</p>
<img src="https://i.loli.net/2020/05/02/3U51STD7iB9tC8w.png" alt="image-20200502104928802" style="zoom:50%;" />

<p>其中 $vp$ 表示 exemplar-positive pair 的 similarity score，$vn$ 表示 exemplar-negative pair 的 similarity score。</p>
<p>本文提出的 triplet loss 定义如下：</p>
<img src="https://i.loli.net/2020/05/02/t9Hm4VrbXUyxWDQ.png" alt="image-20200502104953478" style="zoom:50%;" />

<h2 id="Relationship-between-logistic-loss-and-triplet-loss"><a href="#Relationship-between-logistic-loss-and-triplet-loss" class="headerlink" title="Relationship between logistic loss and triplet loss"></a>Relationship between logistic loss and triplet loss</h2><p>两种损失的区别为：</p>
<img src="https://i.loli.net/2020/05/02/2OVcmUKo9xTAQb4.png" alt="image-20200502105951152" style="zoom:50%;" />

<h3 id="Comparison-on-the-gradients"><a href="#Comparison-on-the-gradients" class="headerlink" title="Comparison on the gradients"></a>Comparison on the gradients</h3><p>对于 logistic loss，梯度为：</p>
<img src="https://i.loli.net/2020/05/02/L3fa4WvtgDCXRu5.png" alt="image-20200502110138148" style="zoom:50%;" />

<p>对于 triplet loss，梯度为：</p>
<img src="https://i.loli.net/2020/05/02/AWtNxcUeI8kudYo.png" alt="image-20200502110212416" style="zoom:50%;" />

<p>这意味着 logistic term 不能充分利用 $vp$ 和 $vn$ 提供的信息。<br>换句话说，$\partial T_l/\partial v_p$ 无法利用来自 $vn$ 的信息，$\partial T_l/\partial v_n$ 无法利用 $vp$ 的信息。</p>
<h2 id="Experimental-results"><a href="#Experimental-results" class="headerlink" title="Experimental results"></a>Experimental results</h2><h3 id="Experiments-on-baseline-trackers"><a href="#Experiments-on-baseline-trackers" class="headerlink" title="Experiments on baseline trackers"></a>Experiments on baseline trackers</h3><p>对三种变体进行对比实验：SiamFC，SiamFC-init，SiamFC-tri。其中 SiamFC-tri 指 在 SiamFC 基础上加了 triplet loss 后继续训练，siamFC-init 指仍使用原始损失继续训练。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/02/CVPR2020-A-Disentangling-Invertible-Interpretation-Network-for-Explaining-Latent-Representations/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhbli">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zhbli">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/02/CVPR2020-A-Disentangling-Invertible-Interpretation-Network-for-Explaining-Latent-Representations/" class="post-title-link" itemprop="url">[CVPR2020] A Disentangling Invertible Interpretation Network for Explaining Latent Representations</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-05-02 09:36:08 / Modified: 10:13:48" itemprop="dateCreated datePublished" datetime="2020-05-02T09:36:08+08:00">2020-05-02</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>现有神经网络的缺点：是黑盒模型，其 hidden representations 缺乏可解释性。</p>
<p>本文的解决方案：将 interpretation 形式化为——从 hidden representation 到 semantic concepts 的转换。</p>
<p>本文提出的  invertible interpretation network 将 hidden representation 分解为单独的语义概念。</p>
<p>此外，本文提出的有效的方法定义语义概念，方法是仅绘制两个图像，同时提供一种无监督的策略。</p>
<h2 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h2><h3 id="Interpreting-Hidden-Representations"><a href="#Interpreting-Hidden-Representations" class="headerlink" title="Interpreting Hidden Representations"></a>Interpreting Hidden Representations</h3><h4 id="Invertible-Transformation-of-Hidden-Representations"><a href="#Invertible-Transformation-of-Hidden-Representations" class="headerlink" title="Invertible Transformation of Hidden Representations"></a>Invertible Transformation of Hidden Representations</h4><p>定义 $f$ 为需要解释的神经网络。$f$ 将输入图像 $x\in \mathbb R^{h\times w\times 3}$ 映射到若干隐层，最终的输出为 $f(x)$。</p>
<p>一个隐层的  intermediate activations $E(x) \in \mathbb R^{H\times W\times C}$ 是图像 $x$ 的 task-specific representation。本文的目的是将这种 hidden representations 转换成人类可理解的表示。</p>
<p>我们定义 $z = E(x) \in \mathbb R^{H\cdot W\cdot C}$ 为需要解释的 hidden representation 的向量表示，长度为 $N=H\cdot W\cdot C$。</p>
<p>将生成 $z$ 之前的子网络定义为 $E$，将生成 $z$ 之后的自网络定义为 $G$：$f(x) = G\odot E(x)$。</p>
<p>为了将 $z$ 转换成 interpretable representation，我们将  distributed representation $z$ 转换成 factorized representation $\tilde z = (\tilde z_k)^K_{k=0} \in \mathbb R^N$。</p>
<p>$\tilde z_k \in \mathbb R^{N_k}, \sum_{k=0}^K N_k=N$，含义是 interpretable concept。</p>
<h4 id="Disentangling-Interpretable-Concepts"><a href="#Disentangling-Interpretable-Concepts" class="headerlink" title="Disentangling Interpretable Concepts"></a>Disentangling Interpretable Concepts</h4><p>$\tilde z_k$ 之间应该是相互独立的，这意味着 joint density 的分解：$p(\tilde z) = \Pi_{k=0}^K p(\tilde z_k)$。</p>
<p>本文指定每个 factor 为正态分布：</p>
<img src="https://i.loli.net/2020/05/02/nFWTm4jxutYqfGb.png" alt="image-20200502101252495" style="zoom:50%;" />
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/27/ICCV2019-Deep-Meta-Learning-for-Real-Time-Target-Aware-Visual-Tracking/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhbli">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zhbli">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/27/ICCV2019-Deep-Meta-Learning-for-Real-Time-Target-Aware-Visual-Tracking/" class="post-title-link" itemprop="url">[ICCV2019] Deep Meta Learning for Real-Time Target-Aware Visual Tracking</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-27 14:52:29" itemprop="dateCreated datePublished" datetime="2020-04-27T14:52:29+08:00">2020-04-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-13 18:19:10" itemprop="dateModified" datetime="2020-05-13T18:19:10+08:00">2020-05-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tracking/" itemprop="url" rel="index"><span itemprop="name">Tracking</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tracking/Meta-Learning/" itemprop="url" rel="index"><span itemprop="name">Meta-Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>现有跟踪算法的问题：需要进行 continuous re-training，而这涉及解决复杂的优化任务以适应目标新的表观。</p>
<p>本文的解决方案：提出基于孪生跟踪器和 meta-learner network 提出了可实时运行的 online 跟踪框架。</p>
<p>meta-learner network 的作用：向孪生网络添加 target-aware feature space，从而提供新的表观信息。</p>
<p>在 5 个数据集上验证了算法有效性，速度为 48 FPS。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>大多数跟踪算法使用深度卷积特征作为特征提取器，并添加用于 <code>on-line adaptation</code> 的分类器或卷积滤波器。</p>
<p>这些算法的缺点：这些算法整合得不够好，两个不同的系统（特征提取器和分类器）分别构建和训练。这就导致分类器需要不断更新以适应目标表观变化，而训练样本有限。这种更新操作需要使用 SGD、Lagrange multipliers、ridge regression 等方法求解复杂的优化问题。这使得跟踪器的运行速度通常在 20 FPS 以下。另外，由于训练样本少，容易导致过拟合。为了解决过拟合问题，大多数算法将手动设计的正则项与  training hyper-parameter tuning scheme 结合在一起，以获得更好的结果。</p>
<p>本文将用于 target search 的 Siamese <code>matching network</code> 和用于 adaptive feature space update 的 meta-learner network 整合到一起，以解决上述问题。对于 meta-learner network，本文提出 parameter prediction network，该网络的设计灵感来自用于解决 few-shot learning 问题的 meta learning 方法。</p>
<p>本文提出的 meta-learner network 为 <code>matching network</code> <strong>提供额外的 convolutional kernels 和 channel attention information</strong>，这样可以自适应的修改 matching network 的特征空间，从而可以在跟踪过程中获得新的表观模板，同时避免过拟合。</p>
<p>给定新的表观训练样本，meta-learner tracker 仅能看到 matching network 最后一层的梯度。</p>
<p>本文还为 meta-learner network 设计了新的训练方式，阻止 meta-learner network 生成导致 matching network 过拟合的新参数，以维持特征空间的泛化能力。</p>
<p>利用 meta-learner network，通过一次前向传播就能构建 target-specific feature space，无需任何迭代优化，同时避免了过拟合，从而提高了跟踪性能。</p>
<h2 id="Tracking-with-Meta-Learner"><a href="#Tracking-with-Meta-Learner" class="headerlink" title="Tracking with Meta-Learner"></a>Tracking with Meta-Learner</h2><h3 id="Overview-of-Proposed-Method"><a href="#Overview-of-Proposed-Method" class="headerlink" title="Overview of Proposed Method"></a>Overview of Proposed Method</h3><h4 id="Components"><a href="#Components" class="headerlink" title="Components"></a>Components</h4><p>定义 $x$ 为表示目标的图像块，$z$ 为包括目标的、具有更大背景区域的图像块。</p>
<p>给定表示目标的图像块 $x$ 和在先前帧获得的 context patches $\mathbf{z}_\delta = {z_1,…,z_M}$，meta-learner network 为 matching network 提供 target-specific weights。为了使权重适应 target patch，本文使用 matching network 的损失函数在最后一层的负梯度 $\delta$（公式2）：</p>
<img src="https://i.loli.net/2020/05/01/2ok7x3jMWDBQTtz.png" alt="image-20200501151253293" style="zoom:50%;" />

<p>其中，$\tilde y_i$ 是 generated binary response map，假设目标位于 $z_i$ 中的正确位置。</p>
<p>Meta-learner network 基于如下事实设计：对于不同的目标，$\delta$ 的特性也不同。因此，将 $\delta$ 作为输入，meta-learner network $g_\theta(\cdot)$ 可以根据输入生成 target-specific weights $w^{target}$（公式3）：</p>
<img src="https://i.loli.net/2020/05/01/RqgTKCUJj6hoHr5.png" alt="image-20200501152811567" style="zoom:50%;" />

<p>新的权重用于更新 matching network 的原始权重（公式4）：</p>
<img src="https://i.loli.net/2020/05/01/Jwm78tETpgQkUvZ.png" alt="image-20200501152928542" style="zoom:50%;" />

<p>其中 $\mathbf w^{adapt} = {w_1,w_2,…,[w_N,w^{target}]}$，将 $w_N$ 和 $w^{target}$ 串接到一起。Meta-learner network 也会为特征图的每个通道生成 channel-wise sigmoid attention weight，用于调整  feature representation space。</p>
<h3 id="Tracking-algorithm"><a href="#Tracking-algorithm" class="headerlink" title="Tracking algorithm"></a>Tracking algorithm</h3><p>给定上一帧的 target patch $x$，可以在当前帧裁剪出 context image $z$。将这两幅图同时送入 matching network，可以获得  estimated response map $\hat y = f_{\mathbf w^{adapt}} (x, z)$。</p>
<p>在跟踪过程中，维护一个 context images 的内存 $\mathbf z_{mem} = {z_1,…,z_K}$，同时维护对应的 estimated response maps 的内存 $\hat {\mathbf y}_{mem}={\hat y_1,…,\hat y_K}$。仅当 response map 中最大值超过阈值 $\tau$ 时，才将对应的 context image 放入内存。</p>
<p>为了更新目标的表观，基于 $\hat {\mathbf y}_{mem}$ 上的 minimum entropy criterion，在内存中选择 $M$ 个样本。该准则避免了有歧义的 response maps：</p>
<img src="https://i.loli.net/2020/05/01/mYKDaJAqRMPeUH6.png" alt="image-20200501160306752" style="zoom:50%;" />

<p>使用 $M$ 个 appearance samples $\mathbf z_\delta$，根据公式 2 和公式 3 获得 target-adaptive weights $w^{target}$。然后利用公式 4 更新 matching network。</p>
<h3 id="Network-Implementation-and-Training"><a href="#Network-Implementation-and-Training" class="headerlink" title="Network Implementation and Training"></a>Network Implementation and Training</h3><h3 id="Matching-Network"><a href="#Matching-Network" class="headerlink" title="Matching Network"></a>Matching Network</h3><p>网络共 5 层，每层的 kernel size、input dimension、output dimension 分别为：</p>
<ol>
<li>$11\times 11 \times 3 \times 128$</li>
<li>$5\times 5 \times 128 \times 256$</li>
<li>$3\times 3 \times 256 \times 384$</li>
<li>$3\times 3 \times 384 \times 256$</li>
<li>$1\times 1 \times 256 \times 192$</li>
</ol>
<h4 id="Meta-Learner-Network"><a href="#Meta-Learner-Network" class="headerlink" title="Meta-Learner Network"></a>Meta-Learner Network</h4><p>Meta-learner network 由三个全连接层组成，其中两个中间层具有 512 个单元。输入和输出分别为：</p>
<ul>
<li><p>输入：gradient $\delta$，尺寸为 $1\times 1\times 256\times 192$。</p>
</li>
<li><p>输出：$w^{target}$，尺寸为 $1\times1\times 256\times 32$。</p>
<p>将 $w_5$ 和 $w^{target}$ 串接起来，得到新的 kernel，尺寸为 $1\times 1\times 256 \times (192+32)$。</p>
</li>
</ul>
<p>为了训练 meta-learner network，使用 ILSVRC 视频数据库验证集的 1314 段视频。训练过程如下：</p>
<ol>
<li>从 object trajectory 中随机采样一个 anchor target image $x$。</li>
<li>从同一个目标的 object trajectory 中随机采样 $M’$ 个 context patches $\mathbf z_{reg} = {z_1,…,z_{M’}}$，其中 $M’ \ge M$。为了避免过拟合，令 $M’ = 2M$。实验中，$M = 8$。</li>
<li>从 $\mathbf z_{reg}$ 中采样 $M$ 个样本构成 $\mathbf z_\delta$。</li>
<li>通过公式 2 获得梯度 $\delta$。</li>
<li>通过最小化损失函数来训练 meta-learner network：</li>
</ol>
<img src="https://i.loli.net/2020/05/01/oJleQ7hOIMVuxzW.png" alt="image-20200501161937898" style="zoom:50%;" />

<p>补充：反传时，更新的是 $\theta$ 的梯度。因为是对 meta-learner network 进行训练。</p>
<h2 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h2><h3 id="Experiments-and-Analysis"><a href="#Experiments-and-Analysis" class="headerlink" title="Experiments and Analysis"></a>Experiments and Analysis</h3><h4 id="Quantitative-Analysis"><a href="#Quantitative-Analysis" class="headerlink" title="Quantitative Analysis"></a>Quantitative Analysis</h4><h5 id="Effect-of-meta-learner-network"><a href="#Effect-of-meta-learner-network" class="headerlink" title="Effect of meta-learner network"></a>Effect of meta-learner network</h5><p>本文提出的算法 MLT 与两个变种 MLT-mt 和 MLT-mt+ft 进行对比：</p>
<ul>
<li>MLT-mt 仅有 matching network，参数固定。</li>
<li>MLT-mt+ft 使用在跟踪时获得的训练样本对 conv5 执行微调。</li>
</ul>
<img src="https://i.loli.net/2020/05/01/6zGYWPbMlcUtaNv.png" alt="image-20200501155543248" style="zoom:50%;" />
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/25/arXiv1804-Adversarial-Attacks-and-Defences-Competition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhbli">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zhbli">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/25/arXiv1804-Adversarial-Attacks-and-Defences-Competition/" class="post-title-link" itemprop="url">[arXiv1804] Adversarial Attacks and Defences Competition</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-25 15:03:00 / Modified: 16:54:12" itemprop="dateCreated datePublished" datetime="2020-04-25T15:03:00+08:00">2020-04-25</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Google Brain 组织了 NIPS 2017 competition，鼓励开发生成对抗样本的新方法，同时鼓励开发相应的防御方法。本文介绍了竞赛的结构和组织，以及一些解决方案。</p>
<h2 id="Adversarial-examples"><a href="#Adversarial-examples" class="headerlink" title="Adversarial examples"></a>Adversarial examples</h2><h3 id="Common-attack-scenarios"><a href="#Common-attack-scenarios" class="headerlink" title="Common attack scenarios"></a>Common attack scenarios</h3><p>可能的对抗攻击场景可以从不同的角度分类。</p>
<p>首先，可以按照攻击的目的分类：</p>
<ul>
<li>Non-targeted attack：对抗的目的是预测任何一个不正确的标签即可。</li>
<li>Targeted attack：预测一个指定的类别。</li>
</ul>
<p>其次，还可以按照 adversary 对模型的了解程度进行分类：</p>
<ul>
<li>White box：了解模型的所有信息，包括模型类型，模型结构，模型参数。</li>
<li>Black box with probing：不了解模型，但可以对模型进行查询：提供输入，观察输出。</li>
<li>Black box without probing：不了解模型的任何信息。</li>
</ul>
<p>第三，可以按将数据送入模型的方式分类：</p>
<ul>
<li>Digital attack：可以直接将入 float32 等的数据送入网络。</li>
<li>Physical attack：仅能通过相机等的结果作为网络的输入。</li>
</ul>
<h3 id="White-box-digital-attacks"><a href="#White-box-digital-attacks" class="headerlink" title="White box digital attacks"></a>White box digital attacks</h3><h4 id="L-BFGS"><a href="#L-BFGS" class="headerlink" title="L-BFGS"></a>L-BFGS</h4><p>优化如下损失：</p>
<img src="https://i.loli.net/2020/04/25/6CnkrEtd8cebFXZ.png" alt="image-20200425153241406" style="zoom:50%;" />

<p>缺点：相当慢。    </p>
<h4 id="Fast-gradient-sign-method-FGSM"><a href="#Fast-gradient-sign-method-FGSM" class="headerlink" title="Fast gradient sign method (FGSM)"></a>Fast gradient sign method (FGSM)</h4><img src="https://i.loli.net/2020/04/25/81UQfdlvGbKcPR2.png" alt="image-20200425153619577" style="zoom:50%;" />

<p>扩展： Basic Iterative Method (BIM) 或称作 Iterative FGSM (I-FGSM)：</p>
<img src="https://i.loli.net/2020/04/25/UYhWg3P7bAJ14TK.png" alt="image-20200425153644273" style="zoom:50%;" />

<p>BIM 可轻松扩展为 target attack，称作 Iterative Target Class Method：</p>
<img src="https://i.loli.net/2020/04/25/NoyH9JOXaE2YFLw.png" alt="image-20200425153710879" style="zoom:50%;" />

<blockquote>
<p>[23] A. Kurakin, I. Goodfellow, and S. Bengio. <strong>Adversarial examples in the physical world</strong>. In ICLR’2017 Workshop, 2016.</p>
</blockquote>
<h4 id="Madry-et-al’s-Attack"><a href="#Madry-et-al’s-Attack" class="headerlink" title="Madry et. al’s Attack"></a>Madry et. al’s Attack</h4><p>通过选择 $\varepsilon$ norm ball 内的随机点最为 starting point，可显著改善 BIM。这种攻击通常称为 projected gradient descent（PGD）。</p>
<blockquote>
<p>[27] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. <strong>Towards deep learning models resistant to adversarial attacks</strong>. In ICLR, 2018.</p>
</blockquote>
<h4 id="Carlini-and-Wagner-attack-C-amp-W"><a href="#Carlini-and-Wagner-attack-C-amp-W" class="headerlink" title="Carlini and Wagner attack (C&amp;W)"></a>Carlini and Wagner attack (C&amp;W)</h4><p>对 L-BFGS 的改进。</p>
<img src="https://i.loli.net/2020/04/25/mOI1LSUPHRxnlVC.png" alt="image-20200425154340241" style="zoom:50%;" />

<blockquote>
<p>[6] N. Carlini and D. Wagner. Towards evaluating the robustness of neural networks. IEEE Symposium on Security and Privacy, 2017.</p>
</blockquote>
<h4 id="Adversarial-transformation-networks-ATN"><a href="#Adversarial-transformation-networks-ATN" class="headerlink" title="Adversarial transformation networks (ATN)"></a>Adversarial transformation networks (ATN)</h4><p>训练生成模型来制作对抗样本。优点是，如果生成模型很小，则比显式优化算法更快生成对抗样本，甚至比 FGSM 更快。</p>
<blockquote>
<p>[1] S. Baluja and I. Fischer. Adversarial transformation networks: Learning to generate adversarial examples. 2017.</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/25/ICLR2015-EXPLAINING-AND-HARNESSING-ADVERSARIAL-EXAMPLES/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhbli">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zhbli">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/25/ICLR2015-EXPLAINING-AND-HARNESSING-ADVERSARIAL-EXAMPLES/" class="post-title-link" itemprop="url">[ICLR2015] EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-25 12:56:08 / Modified: 14:53:22" itemprop="dateCreated datePublished" datetime="2020-04-25T12:56:08+08:00">2020-04-25</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p><a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/pytorch/tutorials/master/beginner_source/fgsm_tutorial.py">https://raw.githubusercontent.com/pytorch/tutorials/master/beginner_source/fgsm_tutorial.py</a></p>
<p>对抗样本：通过对数据集中的样本进行小的、故意的、最坏情况的扰动，使得网络以告置信度输出错误答案。</p>
<p>以前对这种现象的解释集中于非线性和过度拟合。本文认为神经网络容易受到对抗干扰的原始是网络的线性特性。</p>
<p>本文提出了简单快速地生成对抗样本的方法。</p>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>[Szegedy et al. (2014b)] 提出，神经网络易受对抗样本的攻击。</p>
<blockquote>
<p>Szegedy, Christian, Zaremba, Wojciech, Sutskever, Ilya, Bruna, Joan, Erhan, Dumitru, Goodfellow, Ian J., and Fergus, Rob. <strong>Intriguing properties of neural networks</strong>. ICLR, abs/1312.6199, 2014b. URL <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1312.6199">http://arxiv.org/abs/1312.6199</a>.</p>
</blockquote>
<h2 id="THE-LINEAR-EXPLANATION-OF-ADVERSARIAL-EXAMPLES"><a href="#THE-LINEAR-EXPLANATION-OF-ADVERSARIAL-EXAMPLES" class="headerlink" title="THE LINEAR EXPLANATION OF ADVERSARIAL EXAMPLES"></a>THE LINEAR EXPLANATION OF ADVERSARIAL EXAMPLES</h2><p>首先，我们解释线性模型中的对抗样本。在很多问题中，输入特征的精度是受限的。例如，如果像素是 8 位的，则图像会丢弃低于动态范围的 1/255 的所有信息。因为特征的精度有限，因此如果扰动的每个元素 $\pmb{\eta}$ 都小于特征精度，则分类器对于输入 $\pmb{x}$ 和对抗输入 $\tilde{\pmb{x}}=\pmb{x}+\pmb{\eta}$ 的响应不同，这是不合理的。我们希望分类器为 $\pmb{x}$ 和 $\tilde{\pmb x}$ 输出相同类别，只要 $||\pmb \eta||_{\infty}&lt;\epsilon$。</p>
<p>考虑权重向量 $\pmb w$ 和对抗样本的 dot product：</p>
<img src="https://i.loli.net/2020/04/25/fI2FBNwCMYEKbda.png" alt="image-20200425132139129" style="zoom:50%;" />

<p>对抗扰动使得激活增加了 $\pmb w^{\mathsf T}\pmb \eta$。我们可以在 max norm 约束下，令 $\eta=\text{sign}(\pmb w)$ 从而最大化此增量。如果 $\pmb w$ 是 $n$ 维，weight vector 中元素的平均幅值是 $m$，激活将增加 $\epsilon mn$。</p>
<p>虽然 $||\pmb \eta||_{\infty}$ 不会随维数增长，但是由 $\eta$ 引起的扰动噪声的激活变化，会随着 $n$ 线性增加。因此对于高维问题，我们可以对输入进行小的变化，而对输入噪声大的更改。</p>
<p>我们可以将其视为 accidental steganography，其中线性模型被迫处理与其权重最接近的信号，即使存在多个信号，且其他信号具有更大的幅度。</p>
<h2 id="LINEAR-PERTURBATION-OF-NON-LINEAR-MODELS"><a href="#LINEAR-PERTURBATION-OF-NON-LINEAR-MODELS" class="headerlink" title="LINEAR PERTURBATION OF NON-LINEAR MODELS"></a>LINEAR PERTURBATION OF NON-LINEAR MODELS</h2><p>对抗样本的线性解释，指出了生成对抗样本的快速方法。</p>
<p>设 $\pmb \theta$ 是网络参数，$\pmb x$ 是网络输入，$y$ 是对应的 targets，$J(\pmb \theta,\pmb x, y)$ 适用于训练网络的 cost。我们可以在 $\pmb \theta$ 的当前值进行线性化，获得 optimal max-morm constrained pertubation：</p>
<img src="https://i.loli.net/2020/04/25/oHUBDlXVavyC3Ti.png" alt="image-20200425140448919" style="zoom:50%;" />

<p>我们将其称为 <code>fast gradient sign method</code>，用于生成对抗样本。注意，梯度可以通过反向传播进行有效计算。这一简单的算法可以加速对抗网络的训练，或者作为分析神经网络的方法。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/24/CVPR2020-Probabilistic-Regression-for-Visual-Tracking/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zhbli">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zhbli">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/24/CVPR2020-Probabilistic-Regression-for-Visual-Tracking/" class="post-title-link" itemprop="url">[CVPR2020] Probabilistic Regression for Visual Tracking</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-24 19:28:44" itemprop="dateCreated datePublished" datetime="2020-04-24T19:28:44+08:00">2020-04-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-13 18:29:46" itemprop="dateModified" datetime="2020-05-13T18:29:46+08:00">2020-05-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tracking/" itemprop="url" rel="index"><span itemprop="name">Tracking</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tracking/Loss/" itemprop="url" rel="index"><span itemprop="name">Loss</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Abstrat"><a href="#Abstrat" class="headerlink" title="Abstrat"></a>Abstrat</h2><p><a target="_blank" rel="noopener" href="https://github.com/visionml/pytracking">https://github.com/visionml/pytracking</a></p>
<p>现有跟踪算法的问题：表示目标估计的不确定性很重要。现有算法虽然估计了 confidence score，但是缺少清晰的概率解释。</p>
<p>本文的解决方案：提出 probabilistic regression formulation，为目标状态估计 <code>conditional probability density</code>。我们的方法可以建模标签噪声。网络通过最小化 KL 散度进行训练。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>目标跟踪可以建模为一个回归问题。这些跟踪算法的共同做法是：对于<code>一幅图像</code> $x$，给定任意状态 $y$，预测一个 confidence value $s(y,x)$，target state 通过最大化 predicted confidence 来获得：$y^* = \arg\max_ys(y,x)$。</p>
<p>上述提及的 <code>confidence-based regression</code> 方法被 DCF 和孪生跟踪器所共享，这两种方法都在每个<strong>空间位置</strong> $y$ 上执行卷积操作来获得 target confidence $s(y,x)$ 以定位目标。也有些方法进行边框回归：预测 entire target box $y$ 的 confidence $s(y,x)$。</p>
<p><code>confidence-based regression</code> 的一个优点是可以建模不确定性。相反，对于直接回归方法，$y=f(x)$ 让网络做出 single prediction $y$，无法提供其他信息。</p>
<p>然而，confidence value $s(y,x)$ 没有清晰的解释，因为仅仅用于求最大化。因此，取值范围和 predicted confidence 的特性在很大程度上取决于损失函数和用于训练的 <code>pseudo labels</code>。</p>
<h3 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h3><p>我们提出学习预测 <code>conditional probability density</code> $p(y|x)$。与 confidence value $s(y,x)$ 不同，density  $p(y|x)$ 具有清晰直接的解释，允许计算绝对概率。</p>
<h2 id="Regression-by-Confidence-Prediction"><a href="#Regression-by-Confidence-Prediction" class="headerlink" title="Regression by Confidence Prediction"></a>Regression by Confidence Prediction</h2><h3 id="General-Formulation"><a href="#General-Formulation" class="headerlink" title="General Formulation"></a>General Formulation</h3><p>在计算机视觉中，回归是一个基本的问题，用于学习从输入空间 $\mathcal{X}$ 到连续输出空间 $\mathcal{Y}$ 的映射 $f_\theta : \mathcal{X \rightarrow Y}$。</p>
<p>在计算机视觉的一些任务中，会采用直接回归的方法。但是在另一些工作中，网络会预测一个 confidence score。这种 confidence prediction 相比于直接回归由两个好处：</p>
<ol>
<li>confidence prediction 可以捕获输出空间 $\mathcal Y$ 中的不确定性、多假设和歧义。</li>
<li>网络可以利用 $\mathcal{X}$ 和 $\mathcal{Y}$ 共享的对称性，如平移不变性。</li>
</ol>
<p>定义 $\mathcal X$ 为图像空间。</p>
<p>定义 <code>confidence-based regression</code> 为学习一个函数 $s_\theta: \mathcal{Y\times X}\rightarrow \mathbb{R}$，用于预测一个标量置信度得分 $s_\theta (y,x)\in \mathbb{R}$。$(y,x)$ 为 input-output pair。Final estimation $f(x) = y^*$ 通过下式计算：</p>
<img src="https://i.loli.net/2020/04/24/p9kYaRDuE5s3UKW.png" alt="image-20200424193424270" style="zoom:50%;" />

<p>这时，回归问题就转变成了从数据 ${(x_i,y_i)}_i$ 中学习函数 $s_\theta$。这通常需要定义一个 <code>pseudo label</code> $a(y,y_i), a:\mathcal{Y\times Y}\rightarrow\mathbb{R}$，作为 prediction $s_\theta (y,x_i)$ 的 ground-truth confidence value。注意，此处的 $y_i$ 表示图像 $x_i$ 的 ground truth，是一个固定值。而 $y$ 表示空间上的任意位置。</p>
<img src="https://i.loli.net/2020/04/24/l1DGzs5ARI2uYVn.png" alt="image-20200424193438062" style="zoom:50%;" />

<p>其中损失函数 $\ell:\mathbb{R\times R\rightarrow R}$ 表示 predicted confidence value $s_\theta(y,x_i)$ 和对应的 label value $a(y,y_i)$ 之间的差异。实际上，损失函数和 <code>pseudo label functions</code> $a$ 针对不同的任务有多种选择。</p>
<h3 id="In-Visual-Tracking"><a href="#In-Visual-Tracking" class="headerlink" title="In Visual Tracking"></a>In Visual Tracking</h3><p>在目标跟踪中，需要回归的状态通常表示为边框 $y\in\mathbb R^4$。然而由于困难性，以前的方法常常回归边框中点 $y\in\mathbb R^2$。</p>
<p>DCF 跟踪器：</p>
<img src="https://i.loli.net/2020/04/24/HEYuaziDn8xoZJ6.png" alt="image-20200424193451723" style="zoom:50%;" />

<p>其中 $w_\theta$ 是卷积核，$\phi(x)$ 是图像特征。DCF 的损失函数为 $\ell(s,a)=(s-a)^2$。几乎所有的 DCF 方法的 pseudo label 为 $a(y,y_i)=e^{-\frac{||y-y_i||^2}{2\sigma^2}}$。</p>
<p>孪生跟踪器：</p>
<img src="https://i.loli.net/2020/04/24/248BmdOJqrDCMaU.png" alt="image-20200424193502831" style="zoom:50%;" />

<p>孪生跟踪器的损失函数通常为 <code>binary cross entropy loss</code>：</p>
<img src="https://i.loli.net/2020/04/24/KwHlbf81npSrMqN.png" alt="image-20200424193511207" style="zoom:50%;" />

<p>孪生网络的 pseudo label 为 $a(y,y_i)\in[0,1]$。</p>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>本文提出 <code>probabilistic regression model</code>，整合上述 <code>confidence-based regression</code> 的所有优点。与上述方法不同，我们的方法的输出是 <code>predictive probability distribution</code> $p(y|x_i,\theta)$。网络通过优化 predictive density $p(y|x,\theta)$ 和 <code>conditional ground-truth distribution</code> $p(y|y_i)$ 的 KL 散度来训练，这样可以建模标签噪声和任务歧义。$p(y|y_i)$ 取代了 $a$ 的作用。</p>
<h3 id="Representation"><a href="#Representation" class="headerlink" title="Representation"></a>Representation</h3><p>给定输入 $x$，预测输出 $y$ 的 <code>probability distribution</code> $p(y|x,\theta)$。</p>
<img src="https://i.loli.net/2020/04/24/vig5G3JWL2URtTd.png" alt="image-20200424193530376" style="zoom:50%;" />

<p>该公式通过取幂并除以归一化常数，将 $s_\theta$ 转化为 <code>probability density</code>。注意，上式是在任意输出空间 $\mathcal Y$ 上应用 SoftMax 的直接泛化。</p>
<p>给定训练样本对 ${(x_i,y_i)}_i$，最简单的训练方法是最小化 <code>negative log-likelihood</code>：</p>
<img src="https://i.loli.net/2020/04/24/nZ2oYrqLU8MASju.png" alt="image-20200424193542299" style="zoom:50%;" />

<p>接下来讨论该方法的缺点。</p>
<h3 id="Label-Uncertainty-and-Learning-Objective"><a href="#Label-Uncertainty-and-Learning-Objective" class="headerlink" title="Label Uncertainty and Learning Objective"></a>Label Uncertainty and Learning Objective</h3><p>通常采用边框的中心点作为标签。但是有些边框的中心并不具有语义信息。因此使用边框中心点进行训练会产生歧义。另外，标注的边框有时不是特别准。然而这些因素在训练时常常不被考虑。为了解决这一问题，我们通过最小化 KL 散度来训练网络：</p>
<img src="https://i.loli.net/2020/04/24/VtXgPEn5krApIlv.png" alt="image-20200424193601783" style="zoom:50%;" />

<p>该公式描述了两个分布之间的 cross entropy。</p>
<p>补充：KL 散度是两个概率分布之间差别的非对称性度量。当且仅当两个分布相同时，kL 散度等于 0。</p>
<p>与 <code>pseudo label function</code> $a(y|y_i)$ 不同，$p(y|y_i)$ 具有明确的概率分布解释。在高斯模型 $p(y|y_i)=\mathcal N(y|y_i, \sigma^2)$ 的情况下，方差 $\sigma^2$ 可以轨迹为 annotations 的经验方差。本文仅将方差视为超参数。</p>
<p>补充：$p(y|y_i)=\mathcal N(y|y_i, \sigma^2) = \frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(y_i-\mu)^2}{2\sigma^2})$。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/9/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/11/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">zhbli</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">123</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zhbli</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
